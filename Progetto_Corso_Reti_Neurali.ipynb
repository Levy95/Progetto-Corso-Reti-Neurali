{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Levy95/Progetto-Corso-Reti-Neurali/blob/main/Progetto_Corso_Reti_Neurali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gptu6CkmSbgP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gv-BPyfjSwTu"
      },
      "outputs": [],
      "source": [
        "# Device: serve per ottimizzare la computazione di calcoli sulle matrici\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAprA0loUXsM"
      },
      "outputs": [],
      "source": [
        "# Dataset: MNIST.\n",
        "train_dataset_mnist = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train = True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "test_dataset_mnist = torchvision.datasets.MNIST(root='./data',\n",
        "                                                train = False,\n",
        "                                                transform = transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segue un'immagine estratta dal training-set del datset MNIST."
      ],
      "metadata": {
        "id": "51dvc6FxuEjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_dataset_mnist[0]\n",
        "plt.imshow(image[0], cmap='gray')\n",
        "print('Label:', label)"
      ],
      "metadata": {
        "id": "N0_sbxqIFBo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCEiaAx81m1X"
      },
      "outputs": [],
      "source": [
        "# Dataset: FashionMNIST\n",
        "train_dataset_fashionmnist = torchvision.datasets.FashionMNIST(root = './data',\n",
        "                                                               train = True,\n",
        "                                                               transform = transforms.ToTensor(),\n",
        "                                                               download = True)\n",
        "test_dataset_fashionmnist = torchvision.datasets.FashionMNIST(root='./data',\n",
        "                                                              train = True,\n",
        "                                                              transform = transforms.ToTensor())                          "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segue un'immagine estratta dal training-set del datset FashionMNIST."
      ],
      "metadata": {
        "id": "Aqc2aX0guZ8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_dataset_fashionmnist[0]\n",
        "plt.imshow(image[0], cmap='gray')\n",
        "print('Label:', label)"
      ],
      "metadata": {
        "id": "ACu8hSjkFyzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDbPYH68FgcF"
      },
      "outputs": [],
      "source": [
        "# Dataset: CIFAR10\n",
        "train_dataset_cifar10 = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                                      train = True,\n",
        "                                                      transform = transforms.ToTensor(),\n",
        "                                                      download = True)\n",
        "test_dataset_cifar10 = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                                    train = False,\n",
        "                                                    transform = transforms.ToTensor())                                                                                                   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segue un'immagine estratta dal training-set del datset CIFAR10."
      ],
      "metadata": {
        "id": "YB3cSWjXulU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_dataset_cifar10[0]\n",
        "plt.imshow(image[0], cmap='brg')\n",
        "print('Label:', label)"
      ],
      "metadata": {
        "id": "B2CGgFueF80r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguono, nell'ordine, le classi che rappresentano l'implementazione della struttura della rete Feed-Forward con uno e due layer intermedi."
      ],
      "metadata": {
        "id": "a-_sApBSvIdO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WYX4oSH8WStc"
      },
      "outputs": [],
      "source": [
        "# Rete Neurale Feed-Forward completamente connessa con un solo layer: Shallow Network\n",
        "class ReteNeurale1(nn.Module):\n",
        "  def __init__(self,input_size, hidden_size, num_classi, act_func=1):\n",
        "   super(ReteNeurale1, self).__init__()\n",
        "   self.input_size = input_size\n",
        "   self.l1 = nn.Linear(input_size, hidden_size)\n",
        "   self.l2 = nn.Linear(hidden_size, num_classi)\n",
        "   if act_func == 1:\n",
        "    self.actfunc = nn.ReLU()\n",
        "   elif act_func == 2:\n",
        "    self.actfunc = nn.LeakyReLU()\n",
        "   elif act_func == 3:\n",
        "     self.actfunc = nn.Sigmoid() \n",
        "   \n",
        "\n",
        "  def forward(self, x):\n",
        "     out = self.l1(x)\n",
        "     out = self.actfunc(out)\n",
        "     out = self.l2(out)\n",
        "     return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qRWB-Dk92npY"
      },
      "outputs": [],
      "source": [
        "# Rete Neurale Feed-Forward completamente connessa con due layer\n",
        "class ReteNeurale2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size1, hidden_size2, num_classi, act_func=1):\n",
        "    super(ReteNeurale2, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.l1 = nn.Linear(input_size, hidden_size1)\n",
        "    self.l2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "    self.l3 = nn.Linear(hidden_size2, num_classi)\n",
        "    if act_func == 1:\n",
        "      self.actfunc = nn.ReLU()\n",
        "    elif act_func == 2:\n",
        "      self.actfunc = nn.LeakyReLU()\n",
        "    elif act_func == 3:\n",
        "      self.actfunc = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.actfunc(out)\n",
        "    out = self.l2(out)\n",
        "    out = self.actfunc(out)\n",
        "    out = self.l3(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y-4yywP8VdwD"
      },
      "outputs": [],
      "source": [
        "# Funzione che implementa il training di una rete neurale che compie classificazione di immagini.\n",
        "\n",
        "def train_function(rete, load_tr_ds, opt, loss_fun, img_size, num_ep):\n",
        "  # Inputs:\n",
        "  # rete: istanza di una classe di rete neurale\n",
        "  # load_tr_ds: training (loader) set del dataset prescelto\n",
        "  # opt: algoritmo di learning\n",
        "  # img_size: dimensione delle immagini\n",
        "  # num_ep: numero di epoche di training\n",
        "  # Output: loss\n",
        "  n_tot_steps = len(load_tr_ds) # step = len(load_tr_ds)/batch_size\n",
        "  loss_vec = [] # vettore in cui si salvano i valori della loss ad ogni step, serve per il plot\n",
        "  for epoch in range(num_ep):\n",
        "    for i, (immagini, etichette) in enumerate(load_tr_ds):\n",
        "      # si coverte il formato dei dati\n",
        "      immagini = immagini.reshape(-1, img_size).to(device)\n",
        "      etichette = etichette.to(device)\n",
        "\n",
        "      # Forward step: si passano i dati attraverso i layer\n",
        "      outputs = rete(immagini)\n",
        "      # Si calcola la loss\n",
        "      loss = loss_fun(outputs, etichette)\n",
        "      \n",
        "      # Training step: si calcola il gradiente della loss e si compie un passo \n",
        "      # dell'algoritnmo di training\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "       \n",
        "      # si stampano i valori della loss \n",
        "      if (i+1)%100 == 0:\n",
        "        print (f'Epoch [{epoch+1}/{num_ep}], Step [{i+1}/{n_tot_steps}], Loss: {loss.item():.4f}') \n",
        "        loss_vec.append(loss.item()) # salvataggio dei valori della loss ad ogni step\n",
        "        #if loss <= 0.04: # early-stopping\n",
        "         # break\n",
        "        \n",
        "  return loss_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_lcRN0us-LYj"
      },
      "outputs": [],
      "source": [
        "# Funzione che testa una rete neurale neurale allenata per fare classificazione di immagini\n",
        "\n",
        "def test_function(rete, load_ts_ds, img_size):\n",
        "  # Input:\n",
        "  # rete: istanza di una classe di rete neurale\n",
        "  # lead_ts_ds: test (loader) set del dataset prescelto\n",
        "  # img_size: dimensione delle immagini\n",
        "  with torch.no_grad():\n",
        "    num_corrette = 0\n",
        "    num_campioni = 0\n",
        "    for immagini, etichette in load_ts_ds:\n",
        "      immagini = immagini.reshape(-1, img_size).to(device)\n",
        "      etichette = etichette.to(device)\n",
        "      output = rete(immagini)\n",
        "\n",
        "      # max ha come output una tupla del tipo (valore, indice)\n",
        "      _, pred = torch.max(output.data, 1)\n",
        "      num_campioni += etichette.size(0)\n",
        "      num_corrette += (pred == etichette).sum().item()\n",
        "\n",
        "    # accuratezza della rete: percentuali di immagini etichettate correttamente sul campione di dati\n",
        "    acc = 100 * num_corrette/num_campioni\n",
        "    print(f'Accuracy della rete su 10000 immagini test: {acc} %')\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UqjYoRMQjeBV"
      },
      "outputs": [],
      "source": [
        "# Iperparametri\n",
        "input_sizeA = 784 # per immagini 28x28 in scale di grigio\n",
        "input_sizeB = 3072 # per immagini 32x32 in scale RGB\n",
        "img_sizeA = 784\n",
        "img_sizeB = 3072\n",
        "hidden_size1 = 1000\n",
        "hidden_size2 = 500\n",
        "num_classi = 10\n",
        "learning_rate = 0.0001\n",
        "batch_size = 100\n",
        "\n",
        "# Si creano i data-loaders: servono per caricare i dati in batches di dimensioni prestabilite\n",
        "train_loader_mnist = torch.utils.data.DataLoader(dataset=train_dataset_mnist,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle = True)\n",
        "test_loader_mnist = torch.utils.data.DataLoader(dataset= test_dataset_mnist,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "train_loader_fashionmnist = torch.utils.data.DataLoader(dataset = train_dataset_fashionmnist,\n",
        "                                                        batch_size = batch_size,\n",
        "                                                        shuffle=True)\n",
        "test_loader_fashionmnist = torch.utils.data.DataLoader(dataset = test_dataset_fashionmnist,\n",
        "                                                       batch_size = batch_size,\n",
        "                                                       shuffle = False)\n",
        "\n",
        "train_loader_cifar10 = torch.utils.data.DataLoader(dataset = train_dataset_cifar10,\n",
        "                                                   batch_size = batch_size,\n",
        "                                                   shuffle = True)\n",
        "test_loader_cifar10 = torch.utils.data.DataLoader(dataset = test_dataset_cifar10,\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1MkGMPIDhmS"
      },
      "source": [
        "Testiamo la rete neurale con un solo layer intermedio sui dataset MNIST e FashionMNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yzmgH_pUC8ji"
      },
      "outputs": [],
      "source": [
        "# Instanziare la rete neurale scegliendo quale funzione di attivazione si vuole usare\n",
        "rete1 = ReteNeurale1(input_sizeA, hidden_size1, num_classi, act_func=2).to(device)\n",
        "\n",
        "# Scegliere l'algoritmo di learning e la funzione di output e loss\n",
        "alg = torch.optim.Adam(rete1.parameters(), lr = learning_rate)\n",
        "F = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gvPdln9Z83y"
      },
      "outputs": [],
      "source": [
        "print('Dataset MNIST:\\n')\n",
        "l1 = train_function(rete1, train_loader_mnist, alg, F, img_sizeA, 2)\n",
        "a1 = test_function(rete1, test_loader_mnist, img_sizeA) \n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esempio di come si sono eseguiti i grafici relativi al variare della loss durante la fase di training."
      ],
      "metadata": {
        "id": "BX3hrJw0zrNU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f9_C68pC2nSw"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(0, 2, 12)\n",
        "y = l1\n",
        "plt.plot(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWx4wfYWaQOb"
      },
      "outputs": [],
      "source": [
        "print('Dataset FashionMNIST:\\n')\n",
        "l2 = train_function(rete1, train_loader_fashionmnist, alg, F, img_sizeA, 2)\n",
        "a2 = test_function(rete1, test_loader_fashionmnist, img_sizeA)\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e4eOaHjJ5-h"
      },
      "source": [
        "Testiamo la rete neurale con un solo layer sul dataset CIFAR10. E' necessario creare una nuovo oggetto-rete poichè le dimensioni delle immagini di CIFAR10 sono diverse da quelle degli altri due dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w_LSfyiDKAzd"
      },
      "outputs": [],
      "source": [
        "rete1B = ReteNeurale1(input_sizeB, hidden_size1, num_classi, act_func=1).to(device)\n",
        "alg = torch.optim.Adam(rete1B.parameters(), lr = learning_rate)\n",
        "print('Dataset CIFAR10:\\n')\n",
        "l3 = train_function(rete1B, train_loader_cifar10, alg, F, img_sizeB, 2)\n",
        "a3 = test_function(rete1B, test_loader_cifar10, img_sizeB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c86jFZyCL6lG"
      },
      "source": [
        "Allo stesso modo ora testiamo la rete con due layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo_bL8tQL5Zs"
      },
      "outputs": [],
      "source": [
        "rete2 = ReteNeurale2(input_sizeA, hidden_size1, hidden_size2, num_classi, act_func=1).to(device)\n",
        "alg = torch.optim.Adam(rete2.parameters(), lr=learning_rate)\n",
        "\n",
        "print('Dataset MNIST:\\n')\n",
        "l1b = train_function(rete2, train_loader_mnist, alg, F, img_sizeA, 2)\n",
        "a1 = test_function(rete2, test_loader_mnist, img_sizeA) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(0, 2, 12)\n",
        "y = l1b\n",
        "plt.plot(x,y)"
      ],
      "metadata": {
        "id": "Eb-LTspBJHUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY5UzFVtL3qP"
      },
      "outputs": [],
      "source": [
        "print('Dataset FashionMNIST:\\n')\n",
        "l2b = train_function(rete2, train_loader_fashionmnist, alg, F, img_sizeA, 2)\n",
        "a2 = test_function(rete2, test_loader_fashionmnist, img_sizeA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojf7DCVKNhVE"
      },
      "outputs": [],
      "source": [
        "rete2B = ReteNeurale2(input_sizeB, hidden_size1, hidden_size2, num_classi, act_func=1).to(device)\n",
        "alg = torch.optim.Adam(rete2B.parameters(), lr = learning_rate)\n",
        "print('Dataset CIFAR10:\\n')\n",
        "l3b = train_function(rete2B, train_loader_cifar10, alg, F, img_sizeB, 2)\n",
        "a3 = test_function(rete2B, test_loader_cifar10, img_sizeB)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyPDJNH99YlNuGgiF2Wkz9e+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}